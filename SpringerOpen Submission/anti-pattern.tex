%\subsection{OSTIA-Based Verification By-Design}
%This section elaborates on the ways in which OSTIA supports continuous
%architecting. First, we elaborate on the anti-patterns supported in
%OSTIA. Second, we elaborate on the algorithmic analyse-and-refactor actions that OSTIA can
%apply to topologies to provide alternative visualisation and improved topology structure. Third, we discuss how
%OSTIA suggests an alternative architecture to improve the system
%performance. Finally, we elaborate on how OSTIA can drive continuous
%improvement assisted by formal verification. All figures in these sections use a
%simple graph-like notation where nodes may be any topological element (e.g.,
%Spouts or Bolts in Apache Storm terms) while edges are directed data-flow
%connections.

\subsection{Topology Design Anti-Patterns Within OSTIA}\label{sec:anti-pattern}
%\todoMB{inline}{Problema: dobbiamo giustificare perche' questi pattern sono potenzialmente dannosi.}
This section elaborates on the anti-patterns we elicited (See Section \ref{ra}). These anti-patterns are elaborated further within OSTIA to allow for their detection during streaming topology inference analysis. Every pattern is elaborated using a simple graph-like notation where \emph{spouts} are nodes that have outgoing edges only whereas \emph{bolts} are nodes that can have either incoming or outgoing edges.

\subsubsection{Multi-Anchoring}
The Multi-Anchoring pattern is shown in Fig. \ref{fig:multi-anchoring1}. In order to guarantee fault-tolerant stream processing, tuples processed by bolts need to be anchored with the unique {\sf id} of the bolt and be passed to multiple acknowledgers (or ``ackers" in short) in the topology. In this way, ackers can keep track of tuples in the topology. Our practitioners agree that multiple ackers can indeed cause much overhead and influence the operational performance of the entire topology.
%\emph{\bf TODO: what is the consequence of these anti-patterns? How does OSTIA detect?}
%\emph{\bf Multi-anchoring is not supported at the moment. Besides, I am not sure it is an anti-patter but rather a design decision}

%\begin{figure}[H]
%	\begin{center}
%		\includegraphics[width=2.5cm]{images/multi-anchoring}
%		\caption{Multi-anchoring.}
%		\label{fig:multi-anchoring}
%	\end{center}
%\end{figure}

\begin{figure}
\centering 
\subfigure[Multi-anchoring.]{\includegraphics[width=3.5cm,draft]{images/fig2}}\caption{The multi-anchoring anti-pattern.}\label{fig:multi-anchoring1}
%\hspace{1cm}
\subfigure[Cycle-in.]{\includegraphics[width=2.25cm,draft]{images/fig3}}\caption{The cycle-in anti-pattern.}\label{fig:cycle1}
\end{figure}


\subsubsection{Cycle-in Topology}

The Cycle-in pattern is shown in Fig. \ref{fig:cycle1}. Technically, it is possible to have cycle in Storm topologies. An infinite cycle of processing would create an infinite tuple tree and make it impossible for Storm to ever acknowledge spout emitted tuples. Therefore, cycles should be avoided or resulting tuple trees should be investigated additionally to make sure they terminate at some point and under a specified series of conditions (these conditions can be hardcoded in Bolt logic). The anti-pattern itself may lead to infrastructure overloading which in turn incurs in increased costs.
%\emph{\bf A topology is already an infinite stream of tuple, the problem could be the overloading of some machines}
%\emph{\bf At the cycle-detection is not supported (even if it is easy to implement)}

%\begin{figure}[H]
%	\begin{center}
%		\includegraphics[width=2cm]{images/cycle}
%		\caption{Cycle-in Topology.}
%		\label{fig:cycle}
%	\end{center}
%\end{figure}

\subsubsection{Persistent Data}

The persistent data pattern is shown in Fig. \ref{fig:persistence}. This pattern covers the circumstance wherefore if two processing elements need to update a same entity in a storage, there should be a consistency mechanism in place. OSTIA offers limited support to this feature, which we plan to look into more carefully for future work. More details on this support are discussed in the approach limitations section.
%\emph{\bf Ostia does not support this. BTW is this static analysis? if not, is it off-topic?}

\begin{figure}
	\begin{center}
		\includegraphics[width=5cm,draft]{images/fig4}
		\caption{Concurrency management in case of Persistent Data circumstances.}
		\label{fig:persistence}
	\end{center}
\end{figure}


\subsubsection{Computation Funnel}
The computational funnel is shown in Fig. \ref{fig:funnel}. A computational funnel emerges when there is not a path from data source (spout) to the bolts that sends out the tuples off the topology to another topology through a messaging framework or through a storage. This circumstance should be dealt with since it may compromise the availability of results under the desired performance restrictions.

\begin{figure}
	\begin{center}
		\includegraphics[width=6.5cm,draft]{images/fig5}
		\caption{computation funnel.}
		\label{fig:funnel}
	\end{center}
\end{figure}

%\subsection{algorithmic analyse-and-refactor actions  on Stream Topologies}\label{algo}
%
%This section elaborates on the algorithmic analyse-and-refactor actions  supported by OSTIA using the common graph-like notation introduced previously. OSTIA currently supports two topology content analysis (see Sec. \ref{1} and \ref{2}) as well as two topology layout analyses (see Sec. \ref{3} and \ref{4}). Only a part of these analyses is currently implemented in OSTIA. We discuss approach limitations further in Sect. \ref{disc}.\todoMB{}{Frase critica critica da rev. Solo alcune sono implementate.}
%
%\subsubsection{Fan-in/Fan-out}\label{1}
%
%The Fan-in/Fan-out algorithmic analyse-and-refactor action is outlined in Fig. \ref{fig:fan}. For each element of the topology, fan-in is the number of incoming
%streams. Conversely, fan-out is the number outgoing streams. In the case of
%bolts, both in and out streams are internal to the topology. For Spouts,
%incoming streams are the data sources of the topology (e.g., message brokers,
%APIs, etc) which live outside of the topology.
%
%\begin{figure}
%	\begin{center}
%		\includegraphics[width=3cm]{images/fan-in-out}
%		\caption{Fan-in fan-out in Stream topologies.}
%		\label{fig:fan}
%	\end{center}
%\end{figure}
%
%This algorithmic analyse-and-refactor action allows to visualise instances where fan-in and fan-out numbers are differing.\todoMB{}{Solo visual quindi.}
%
%\subsubsection{Topology cascading}\label{2}
%
%The Cascading algorithmic analyse-and-refactor action is outlined in Fig. \ref{fig:cascading}. By topology cascading, we mean connecting two different Storm topologies via a messaging framework (e.g., Apache Kafka~\cite{kafka}).
%%\footnote{\url{http://kafka.apache.org/}}). 
%Although cascading may simplify the development of topologies by encouraging architecture elements' reuse especially for complex but procedural topologies, this circumstance may well raise the complexity of continuous architecting and may require separation of concerns \cite{soc}. For example, Fig. \ref{fig:cascading} outlines an instance in which two topologies are concatenated together by a message broker. In this instance, formal verification may be applied on the left-hand side topology, which is more business-critical, while the right-hand side of the entire topology is improved by on-the-fly OSTIA-based analysis. Even though OSTIA support for this feature is still limited, we report it nonetheless since OSTIA was engineered to address multiple topologies at once. 
%%More details on this and similar limitations are discussed in Section \ref{lim}.
%%\emph{\bf Ostia does not support this. I can't think of an easy way to implement it}
%
%\begin{figure}
%	\begin{center}
%		\includegraphics[width=6cm]{images/cascading}
%		\caption{cascading.}
%		\label{fig:cascading}
%	\end{center}
%\end{figure}
%
%This algorithmic action allows to combine multiple cascading topologies.\todoMB{}{Non mi e' chiaro cosa faccia questa azione? E' visuale?}

%REMOVED MOVED TO CASE-STUDY ANALYSIS 
%\subsubsection{Topology clustering}\label{3}
%Topology clustering is outlined in Fig. \ref{fig:clustering}. Topology clustering implies identifying coupled processing elements (i.e., bolts and spouts) and cluster them together (e.g., by means of graph-based analysis) in a way that elements in a cluster have high cohesion and loose-coupling with elements in other clusters. Simple clustering or Social-Network Analysis mechanisms can be used to infer clusters. These clusters may require additional attention since they could turn out to become bottlenecks. Reasoning more deeply on clusters and their resolution may lead to establishing the Storm scheduling policy best-fitting with the application. We will elaborate on this in Section \ref{sec:performance-boosting}.
%%\emph{\bf Does it relates with Storm scheduling?}
%
%\begin{figure}
%	\begin{center}
%		\includegraphics[width=6.5cm]{images/clustering}
%		\caption{clustering.}
%		\label{fig:clustering}
%	\end{center}
%\end{figure}


%REMOVED MOVED TO CASE-STUDY ANALYSIS 
%\subsubsection{Linearising a topology}\label{4}
%
%Topology linearisation is outlined in Fig. \ref{fig:linearizing}. Sorting the processing elements in a topology in a way that topology looks more linear, visually. This step ensures that visual investigation and evaluation of the structural complexity of the topology is possible by direct observation. It is sometimes essential to provide such a visualisation to evaluate how to refactor the topology as needed.

%\begin{figure}
%	\begin{center}
%		\includegraphics[width=5cm]{images/linearizing}
%		\caption{linearising.}
%		\label{fig:linearizing}
%	\end{center}
%\end{figure}


% SECTION HEURISTICS REMOVED FOR SAFETY REASONS
%%%\subsection{Performance Improvement Heuristics}
%%%\label{sec:performance-boosting}
%%%In this section, we elaborate on a specific case where algorithmic analyse-and-refactor actions improve the performance of the data-intensive application. More in particular, big data architectures typically need parameters tuning to achieve best
%%%performance. For instance, in Storm developers have to specify the parallelism
%%%level for each node, which is the number of processes instantiated for a
%%%particular bolt or spout. OSTIA provides suggestions on how to change the
%%%parallelism level of the nodes, using simple and fast heuristics together with
%%%static analysis.
%%%
%%%After architects designed a Storm application, a scheduler instantiates the
%%%topology on a cluster of machines. The default scheduler utilises a round-robin
%%%strategy to fairly load the machines with the bolts and spouts. This a crucial
%%%assumption for the heuristic used in OSTIA to perform well. There are several
%%%proposals in the state of the art to change the default scheduler logic in order to boost the performance of the topologies \cite{Aniello2013Adaptive, R-Storm2015Peng}. However, many DIA users typically prefer the default scheduler, while having the opportunity to tune the parameters automatically behind the scenes.
%%%
%%%The OSTIA heuristic works as follows: A DIA architect runs OSTIA specifying the
%%%number of machines used in the deployment and the number of instances of spouts
%%%and bolts that can be spawned in each machine. OSTIA statically analyses the
%%%topology and extracts the parallelism level for each component of the
%%%topology. At this point, we sum of all instances need to be allocated and the
%%%slots available on the machines ($machines * components\_for\_each\_machine$).\todoMB{}{Qui mi sfugge il concetto di slot.}
%%%
%%%OSTIA decides whether improvements are possible (i.e. \emph{slots
%%%  available} $>$ \emph{instances to be allocate}), and suggests changes to the
%%%parallelism level to the nodes in order to improve the performance. The simplest
%%%case occurs when the unallocated slots are enough to remove a machine from the
%%%cluster, thus saving costs.
%%%
%%%Alternatively, OSTIA identifies a subset of nodes, called critical nodes, which
%%%are important from a performance perspective. The critical nodes of a topology
%%%are defined as the nodes with the highest \emph{weighted fan-in}. The
%%%\emph{weighted fan-in} of a node \emph{N} is defined by Equation \ref{eq:wfi}.
%%%
%%%\begin{align}
%%%  \text{weighted fan-in(N)} = \frac{\sum_{X \rightarrow N \in Edges} parallelism(X)}{parallelism(N)} \label{eq:wfi}
%%%\end{align}
%%%
%%%The critical nodes could be easily susceptible to overloading as their
%%%parallelism level do not compensate the parallelism level of its
%%%\emph{in-nodes}. Increasing the parallelism level gives the nodes more resources
%%%to cope with high loads.
%%%
%%%For instance, let us take Figure \ref{topo1} as an example. There are 22
%%%components that need to be allocated.\todoMB{}{Forse e' meglio parlare di threads invece che components?} Suppose that our cluster is composed by 4
%%%machines and each machine fits 10 instances of components. OSTIA in this case
%%%would suggest to simply remove one machine. Let us suppose that we have 3
%%%machines with 10 tasks each. At this point we have 30 slots available and 22
%%%components, therefore we have 8 slots available that can be used to increase the
%%%performance. In order to decide the components to improves we identify the ones
%%%with maximum \emph{weighted fan-in}. In the example nodes \emph{mediaExtractor}
%%%and \emph{articleExtractor} with \emph{weighted fan-in} of 8. Finally, since we
%%%have 8 free slots to share between two nodes\todoMB{}{Nodi, bolts?} we increase the parallelism level
%%%of the two critical nodes of $8/2 = 4$, setting it from 1 to 5.
%%%
%%%The above heuristic approach concludes the support that OSTIA offers to quickly and continuously improving streaming topologies by means of algorithmic evaluations and analysis. Conversely, as previously stated we learned from industrial practice that the need might rise for more formal guarantees, e.g., concerning some key parts of a streaming topology with respect to key big-data properties such as queue-boundedness - i.e., a guarantee that the queue for a certain bolt will always be bounded - or queue-population - i.e., a guarantee that the queue never contains privacy sensitive objects. In similar scenarios, OSTIA offers the seamless capability of running complex and exhaustive formal verification over analysed topologies. The next section elaborates further on this key support offered by OSTIA.

%
%\comment{PJ: Should we put this section into a separate section? I feel it is disconnected to the content of this section.}
\subsection{OSTIA-Based Formal Verification}\label{ver}
\input{macros}

This section describes the formal modelling and verification employed in OSTIA. Our assumption for DIA refactoring is that architects eliciting and studying their topologies by means of OSTIA may want to continuously and incrementally improve it based on results from solid verification approaches. The approach, which was first proposed in \cite{MBER16}, relies on \textit{satisfiability checking}~\cite{MPS13}, an alternative approach to model-checking where, instead of an operational model (like automata or transition systems), the system (i.e., a topology in this context) is specified by a formula defining its executions over time and properties are verified by proving that the system logically entails them.

%The logic we use is Constraint LTL over clocks 
CLTLoc is a real-time temporal logic and, in particular, a semantic restriction of Constraint LTL (CLTL)~\cite{DD07} allowing atomic formulae over $(\mathbb{R}, \set{<,=})$ where the arithmetical variables behave like clocks of Timed Automata (TA)~\cite{timed}.
As for TA, clocks measures time delays between events: a clock $x$ measures the time elapsed since the last time when $x=0$ held, i.e., since the last ``reset'' of $x$.
Clocks are interpreted over Reals and their value can be tested with respect to a positive integer value or reset to 0.
%
To analyse anomalous executions of Storm topologies which do not preserve the queue-length boundedness property for the nodes of the application, we consider CLTLoc with counters.
Counters are discrete non-negative variables that are used in our model to represent the length of bolt queues over the time throughout the streaming processing realized by the application.
Let $X$ be a finite set of clock variables $x$ over $\Real$, $Y$ be a finite set of variables over $\Nat$ and $AP$ be a finite set of atomic propositions $p$.
CLTLoc formulae with counters are defined as follows:
\begin{equation*}%\small
  \phi :=
  \begin{gathered}
    p \mid x\sim c \mid y\sim c\mid \aX y\sim z\pm c \mid\phi \wedge \phi \mid \neg \phi \mid \\
       \X{\phi} \mid \Y{\phi} %\mid \Zed\phi
\mid \phi\U\phi \mid \phi\Snc\phi
  \end{gathered}
\end{equation*}
where $x \in X$, $y,z \in Y$, $c \in \Nat$ and 
$\sim \in \set{<,=}$, $\mathbf{X}$, $\mathbf{Y}$, $\U$ and $\Snc$ are the
usual ``next'', ``previous'', ``until'' and ``since''.
%The semantics of CLTLoc is defined with respect to $(\Real, \set{<,=})$ and $\pair{\Nat}{<}$, the latter representing positions in time.
A \textit{model} is a pair $\pair{\pi}{\sigma}$, where $\sigma$ is a mapping associating every variable $x$ and position in $\Nat$ with value $\sigma(i,x)$ and $\pi$ is a mapping associating each position in $\Nat$ with subset of $AP$. 
The semantics of CLTLoc is defined as for LTL except for formulae $x\sim c$ and $\aX y \sim z\pm c$. 
%At position $i\in\Nat$, $ \pair{\pi}{\sigma}, i \models x\sim c \textbf{ iff }  \sigma(i, x)\sim c$ and $\pair{\pi}{\sigma}, i \models \aX y\sim z \pm c \textbf{ iff }  \sigma(i+1, z) \sim \sigma(i,z) \pm c$.
Intuitively, formula $x\sim c$ states that the value of clock $x$ is $\sim$ than/to $c$ and formula $\aX y \sim z\pm c$ states that the next value of variable $y$ is $\sim$ to/than $z+c$.

The standard technique to prove the satisfiability of CLTL and CLTLoc formulae is based on of B\"uchi automata \cite{DD07,BRS15} %the evidence has turned out that it may be rather expensive in practice, even in the case of LTL (the size of the automaton is exponential with respect to the size of the formula).
but, for practical implementation, Bounded Satisfiability Checking (BSC)~\cite{MPS13} avoids the onerous construction of automata by means of a reduction to a decidable Satisfiability Modulo Theory (SMT) problem~\cite{BRS15}.
%By unrolling the semantics of a formula for a finite number $k>0$ of steps, 
The outcome of a BSC problem is either an infinite ultimately periodic model or unsat.
%\cite{BRS15} shows that BSC for CLTLoc is complete and that is reducible to a decidable Satisfiability Modulo Theory (SMT) problem. 
%A CLTLoc formula can be translated into the decidable theory of quantifier-free formulae with equality and uninterpreted functions combined with the theory of Reals over $(\Real,<)$. %, written QF-EUF$(\Real,<)$.

CLTLoc allows the specification of non-deterministic models using temporal constraints wherein clock variables range over a dense domain and whose value is not abstracted.
Clock variables represent, in the logical language and with the same precision, physical (dense) clocks implemented in real architectures.
%They appear in formulae in the form $x \sim c$ to express a bound $c$ on the delay measured by clock $x$. 
Clocks are associated with specific events to measure time elapsing over the executions.
As they are reset when the associated event occurs, in any moment, the clock value represents the time elapsed since the previous reset and corresponds to the elapsed time since the last occurrence of the event associated to it.
We use such constraints to define, for instance, the time delay required to process tuples or between two node failures.\\

%Modeling topologies requires to express by formulae emitting rates which measure the number of tuples emitted by a spout node per time unit.
%***TBC

\input{verification}


